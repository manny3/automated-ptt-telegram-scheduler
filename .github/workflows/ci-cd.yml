name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  NODE_VERSION: '18'
  GOOGLE_CLOUD_PROJECT: ${{ secrets.GOOGLE_CLOUD_PROJECT }}
  # Enhanced CI configuration
  NPM_CONFIG_LEGACY_PEER_DEPS: true
  NPM_CONFIG_AUDIT_LEVEL: moderate
  NPM_CONFIG_FUND: false
  FORCE_COLOR: 1

jobs:
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        node-version: ['18', '20']
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
        cache-dependency-path: package-lock.json

    - name: Enhanced multi-layer caching strategy
      uses: actions/cache@v4
      with:
        path: |
          ~/.npm
          node_modules
          .next/cache
          .jest-cache
          coverage
          .swc
          .eslintcache
        key: ${{ runner.os }}-node-${{ matrix.node-version }}-deps-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('jest.config.js', 'next.config.js', 'tsconfig.json') }}-v2
        restore-keys: |
          ${{ runner.os }}-node-${{ matrix.node-version }}-deps-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('jest.config.js', 'next.config.js', 'tsconfig.json') }}-
          ${{ runner.os }}-node-${{ matrix.node-version }}-deps-${{ hashFiles('**/package-lock.json') }}-
          ${{ runner.os }}-node-${{ matrix.node-version }}-deps-
          ${{ runner.os }}-node-${{ matrix.node-version }}-

    - name: Cache build artifacts
      uses: actions/cache@v4
      with:
        path: |
          .next/static
          .next/standalone
          .next/cache
        key: ${{ runner.os }}-build-${{ matrix.node-version }}-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('src/**/*', 'pages/**/*', 'components/**/*') }}
        restore-keys: |
          ${{ runner.os }}-build-${{ matrix.node-version }}-${{ hashFiles('**/package-lock.json') }}-
          ${{ runner.os }}-build-${{ matrix.node-version }}-

    - name: Display environment diagnostics
      run: |
        echo "=== Environment Information ==="
        echo "Node.js version: $(node --version)"
        echo "npm version: $(npm --version)"
        echo "Platform: $(uname -a)"
        echo "Available memory: $(free -h || echo 'N/A')"
        echo "Available disk space: $(df -h . || echo 'N/A')"
        echo "Current directory: $(pwd)"
        echo "Environment variables:"
        env | grep -E '^(NODE_|NPM_|CI|GITHUB_)' | sort
        echo "================================"

    - name: Validate package files
      run: |
        echo "=== Package File Validation ==="
        if [ ! -f package.json ]; then
          echo "‚ùå Error: package.json not found"
          exit 1
        fi
        echo "‚úÖ package.json exists"
        
        if [ ! -f package-lock.json ]; then
          echo "‚ùå Error: package-lock.json not found"
          exit 1
        fi
        echo "‚úÖ package-lock.json exists"
        
        # Validate JSON syntax
        if ! node -e "JSON.parse(require('fs').readFileSync('package.json', 'utf8'))"; then
          echo "‚ùå Error: package.json has invalid JSON syntax"
          exit 1
        fi
        echo "‚úÖ package.json has valid JSON syntax"
        
        if ! node -e "JSON.parse(require('fs').readFileSync('package-lock.json', 'utf8'))"; then
          echo "‚ùå Error: package-lock.json has invalid JSON syntax"
          exit 1
        fi
        echo "‚úÖ package-lock.json has valid JSON syntax"
        echo "================================"

    - name: Install dependencies with enhanced error handling
      run: |
        echo "=== Dependency Installation ==="
        ./scripts/install-dependencies.sh
      env:
        CI: true
        NODE_ENV: test

    - name: Validate dependency installation
      run: |
        echo "=== Dependency Validation ==="
        ./scripts/validate-dependencies.sh
        
        # Additional validation
        echo "Checking critical dependencies..."
        npm list react @testing-library/react jest typescript next --depth=0 || {
          echo "‚ùå Critical dependencies missing or invalid"
          echo "Full dependency tree:"
          npm list --depth=0
          exit 1
        }
        echo "‚úÖ All critical dependencies validated"

    - name: Run linting with detailed output
      run: |
        echo "=== ESLint Analysis ==="
        npm run lint -- --format=compact --max-warnings=0 || {
          echo "‚ùå Linting failed"
          echo "Running lint with detailed output for debugging..."
          npm run lint -- --format=stylish || true
          exit 1
        }
        echo "‚úÖ Linting passed"

    - name: Run type checking with detailed output
      run: |
        echo "=== TypeScript Type Checking ==="
        npm run type-check || {
          echo "‚ùå Type checking failed"
          echo "TypeScript configuration:"
          cat tsconfig.json
          exit 1
        }
        echo "‚úÖ Type checking passed"

    - name: Run tests in parallel with performance monitoring
      run: |
        echo "=== Parallel Test Execution ==="
        echo "Starting parallel test execution at $(date)"
        
        # Record start time for performance monitoring
        echo "TEST_START_TIME=$(date +%s)" >> $GITHUB_ENV
        
        # Run tests in parallel using background processes
        (
          echo "Starting unit tests..."
          npm run test:unit -- --verbose --detectOpenHandles --forceExit --maxWorkers=2 > unit-test.log 2>&1
          echo $? > unit-test.exit
        ) &
        UNIT_PID=$!
        
        (
          echo "Starting integration tests..."
          npm run test:integration -- --verbose --detectOpenHandles --forceExit --maxWorkers=2 > integration-test.log 2>&1
          echo $? > integration-test.exit
        ) &
        INTEGRATION_PID=$!
        
        (
          echo "Starting E2E tests..."
          npm run test:e2e -- --verbose --detectOpenHandles --forceExit --maxWorkers=1 > e2e-test.log 2>&1
          echo $? > e2e-test.exit
        ) &
        E2E_PID=$!
        
        (
          echo "Starting performance tests..."
          npm run test:performance -- --verbose --detectOpenHandles --forceExit --maxWorkers=1 > performance-test.log 2>&1
          echo $? > performance-test.exit
        ) &
        PERFORMANCE_PID=$!
        
        # Wait for all tests to complete
        echo "Waiting for all test suites to complete..."
        wait $UNIT_PID $INTEGRATION_PID $E2E_PID $PERFORMANCE_PID
        
        # Record end time
        echo "TEST_END_TIME=$(date +%s)" >> $GITHUB_ENV
        
        # Check results
        UNIT_EXIT=$(cat unit-test.exit)
        INTEGRATION_EXIT=$(cat integration-test.exit)
        E2E_EXIT=$(cat e2e-test.exit)
        PERFORMANCE_EXIT=$(cat performance-test.exit)
        
        echo "=== Test Results Summary ==="
        echo "Unit Tests: $([ $UNIT_EXIT -eq 0 ] && echo "‚úÖ PASSED" || echo "‚ùå FAILED")"
        echo "Integration Tests: $([ $INTEGRATION_EXIT -eq 0 ] && echo "‚úÖ PASSED" || echo "‚ùå FAILED")"
        echo "E2E Tests: $([ $E2E_EXIT -eq 0 ] && echo "‚úÖ PASSED" || echo "‚ùå FAILED")"
        echo "Performance Tests: $([ $PERFORMANCE_EXIT -eq 0 ] && echo "‚úÖ PASSED" || echo "‚ùå FAILED")"
        
        # Display logs for failed tests
        if [ $UNIT_EXIT -ne 0 ]; then
          echo "=== Unit Test Logs ==="
          cat unit-test.log
        fi
        
        if [ $INTEGRATION_EXIT -ne 0 ]; then
          echo "=== Integration Test Logs ==="
          cat integration-test.log
        fi
        
        if [ $E2E_EXIT -ne 0 ]; then
          echo "=== E2E Test Logs ==="
          cat e2e-test.log
        fi
        
        if [ $PERFORMANCE_EXIT -ne 0 ]; then
          echo "=== Performance Test Logs ==="
          cat performance-test.log
        fi
        
        # Exit with error if any test failed
        if [ $UNIT_EXIT -ne 0 ] || [ $INTEGRATION_EXIT -ne 0 ] || [ $E2E_EXIT -ne 0 ] || [ $PERFORMANCE_EXIT -ne 0 ]; then
          echo "‚ùå One or more test suites failed"
          exit 1
        fi
        
        echo "‚úÖ All test suites passed"
      env:
        NODE_ENV: test
        JEST_WORKERS: 50%

    - name: Generate comprehensive test coverage with performance metrics
      run: |
        echo "=== Test Coverage Generation ==="
        COVERAGE_START_TIME=$(date +%s)
        
        npm run test:coverage -- --detectOpenHandles --forceExit --maxWorkers=50% || {
          echo "‚ùå Coverage generation failed"
          exit 1
        }
        
        COVERAGE_END_TIME=$(date +%s)
        COVERAGE_DURATION=$((COVERAGE_END_TIME - COVERAGE_START_TIME))
        
        # Display coverage summary
        if [ -f coverage/coverage-summary.json ]; then
          echo "Coverage Summary:"
          cat coverage/coverage-summary.json | jq '.total'
        fi
        
        echo "‚úÖ Coverage generation completed in ${COVERAGE_DURATION}s"
        echo "COVERAGE_DURATION=${COVERAGE_DURATION}" >> $GITHUB_ENV

    - name: Generate CI performance report
      run: |
        echo "=== CI Performance Report ==="
        
        # Calculate test execution time
        TEST_DURATION=$((${TEST_END_TIME:-0} - ${TEST_START_TIME:-0}))
        TOTAL_DURATION=$(($(date +%s) - ${WORKFLOW_START_TIME:-$(date +%s)}))
        
        # Create performance report
        cat > ci-performance-report.md << EOF
        # CI Performance Report
        
        **Workflow Information:**
        - Run ID: ${{ github.run_id }}
        - Node Version: ${{ matrix.node-version }}
        - Commit: ${{ github.sha }}
        - Branch: ${{ github.ref_name }}
        
        **Performance Metrics:**
        - Total Workflow Duration: ${TOTAL_DURATION}s
        - Test Execution Duration: ${TEST_DURATION}s
        - Coverage Generation Duration: ${COVERAGE_DURATION:-0}s
        - Cache Hit Rate: $([ -d ~/.npm ] && echo "High" || echo "Low")
        
        **Resource Usage:**
        - Available Memory: $(free -h | grep Mem | awk '{print $7}')
        - Disk Usage: $(df -h . | tail -1 | awk '{print $5}')
        - CPU Cores: $(nproc)
        
        **Optimization Status:**
        - ‚úÖ Multi-layer caching enabled
        - ‚úÖ Parallel test execution
        - ‚úÖ Performance monitoring
        - ‚úÖ Resource optimization
        
        **Recommendations:**
        $([ $TEST_DURATION -gt 300 ] && echo "- ‚ö†Ô∏è Test execution time is high (${TEST_DURATION}s) - consider further optimization" || echo "- ‚úÖ Test execution time is optimal")
        $([ $TOTAL_DURATION -gt 900 ] && echo "- ‚ö†Ô∏è Total workflow time is high (${TOTAL_DURATION}s) - review caching strategy" || echo "- ‚úÖ Total workflow time is acceptable")
        EOF
        
        echo "Performance report generated:"
        cat ci-performance-report.md
        
        # Set environment variables for later use
        echo "TEST_DURATION=${TEST_DURATION}" >> $GITHUB_ENV
        echo "TOTAL_DURATION=${TOTAL_DURATION}" >> $GITHUB_ENV
      env:
        WORKFLOW_START_TIME: ${{ github.event.head_commit.timestamp }}

    - name: Upload test results and performance data
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-node-${{ matrix.node-version }}
        path: |
          coverage/
          test-results/
          junit.xml
          ci-performance-report.md
          *-test.log
        retention-days: 7

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      if: matrix.node-version == '18'
      with:
        file: ./coverage/lcov.info
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
        verbose: true

    - name: Test failure diagnostics
      if: failure()
      run: |
        echo "=== Test Failure Diagnostics ==="
        echo "Node.js version: $(node --version)"
        echo "npm version: $(npm --version)"
        echo "Available memory: $(free -h || echo 'N/A')"
        echo "Available disk space: $(df -h . || echo 'N/A')"
        
        echo "Recent npm logs:"
        if [ -f ~/.npm/_logs/*.log ]; then
          tail -50 ~/.npm/_logs/*.log || echo "No npm logs found"
        fi
        
        echo "Jest cache info:"
        if [ -d .jest-cache ]; then
          ls -la .jest-cache/ || echo "Jest cache directory empty"
        fi
        
        echo "Process information:"
        ps aux | head -20 || echo "Process info unavailable"
        
        echo "================================"

  security:
    name: Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: package-lock.json

    - name: Enhanced security scan caching
      uses: actions/cache@v4
      with:
        path: |
          ~/.npm
          node_modules
        key: ${{ runner.os }}-security-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}
        restore-keys: |
          ${{ runner.os }}-security-node-${{ env.NODE_VERSION }}-
          ${{ runner.os }}-security-node-

    - name: Install dependencies with enhanced error handling
      run: |
        echo "=== Security Scan Dependencies Installation ==="
        ./scripts/install-dependencies.sh
      env:
        CI: true

    - name: Run security audit with detailed reporting
      run: |
        echo "=== NPM Security Audit ==="
        npm audit --audit-level high --json > audit-results.json || {
          echo "‚ùå Security vulnerabilities found"
          echo "Audit results:"
          cat audit-results.json | jq '.vulnerabilities // empty'
          exit 1
        }
        echo "‚úÖ No high-severity vulnerabilities found"

    - name: Run dependency vulnerability scan
      run: |
        echo "=== Dependency Vulnerability Scan ==="
        if [ -f audit-ci.json ]; then
          npx audit-ci --config audit-ci.json || {
            echo "‚ùå Vulnerability scan failed"
            exit 1
          }
        else
          echo "‚ö†Ô∏è audit-ci.json not found, using default configuration"
          npx audit-ci --moderate || {
            echo "‚ùå Vulnerability scan failed"
            exit 1
          }
        fi
        echo "‚úÖ Vulnerability scan passed"

    - name: Upload security scan results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-scan-results
        path: |
          audit-results.json
        retention-days: 30

    - name: Run SAST scan with enhanced configuration
      uses: github/super-linter@v5
      env:
        DEFAULT_BRANCH: main
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        VALIDATE_TYPESCRIPT_ES: true
        VALIDATE_JAVASCRIPT_ES: true
        VALIDATE_JSON: true
        VALIDATE_YAML: true
        VALIDATE_DOCKERFILE: true
        VALIDATE_BASH: true
        LOG_LEVEL: WARN
        SUPPRESS_POSSUM: true

  build:
    name: Build Application
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [test, security]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: package-lock.json

    - name: Enhanced build caching with multiple layers
      uses: actions/cache@v4
      with:
        path: |
          ~/.npm
          node_modules
          .next/cache
          .next/static
          .next/standalone
          .swc
        key: ${{ runner.os }}-build-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('next.config.js', 'tsconfig.json', 'tailwind.config.js') }}-v2
        restore-keys: |
          ${{ runner.os }}-build-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('next.config.js', 'tsconfig.json', 'tailwind.config.js') }}-
          ${{ runner.os }}-build-node-${{ env.NODE_VERSION }}-${{ hashFiles('**/package-lock.json') }}-
          ${{ runner.os }}-build-node-${{ env.NODE_VERSION }}-
          ${{ runner.os }}-build-node-

    - name: Cache Docker layers
      uses: actions/cache@v4
      with:
        path: /tmp/.buildx-cache
        key: ${{ runner.os }}-buildx-${{ github.sha }}
        restore-keys: |
          ${{ runner.os }}-buildx-

    - name: Install dependencies with enhanced error handling
      run: |
        echo "=== Build Dependencies Installation ==="
        ./scripts/install-dependencies.sh
      env:
        CI: true

    - name: Build Next.js application with detailed logging
      run: |
        echo "=== Next.js Build Process ==="
        echo "Build environment:"
        echo "  NODE_ENV: production"
        echo "  Next.js version: $(npm list next --depth=0 2>/dev/null | grep next || echo 'Unknown')"
        echo "  Available memory: $(free -h || echo 'N/A')"
        echo "  Available disk space: $(df -h . || echo 'N/A')"
        
        npm run build || {
          echo "‚ùå Build failed"
          echo "Build logs and diagnostics:"
          if [ -f .next/build-manifest.json ]; then
            echo "Build manifest exists"
          else
            echo "Build manifest missing"
          fi
          exit 1
        }
        
        echo "‚úÖ Build completed successfully"
        echo "Build output size:"
        du -sh .next/ || echo "Unable to calculate build size"
      env:
        NODE_ENV: production

    - name: Set up Docker Buildx for enhanced caching
      uses: docker/setup-buildx-action@v3
      with:
        driver-opts: |
          network=host

    - name: Build Docker image with enhanced caching and parallel processing
      run: |
        echo "=== Docker Image Build with Enhanced Caching ==="
        echo "Docker version: $(docker --version)"
        echo "Available disk space: $(df -h . || echo 'N/A')"
        echo "CPU cores available: $(nproc)"
        
        BUILD_START_TIME=$(date +%s)
        
        # Build with buildx for better caching and parallel processing
        docker buildx build \
          --cache-from=type=local,src=/tmp/.buildx-cache \
          --cache-to=type=local,dest=/tmp/.buildx-cache-new,mode=max \
          --load \
          --tag ptt-telegram-scheduler:${{ github.sha }} \
          --tag ptt-telegram-scheduler:latest \
          --build-arg BUILDKIT_INLINE_CACHE=1 \
          . || {
          echo "‚ùå Docker build failed"
          echo "Docker system info:"
          docker system df || echo "Unable to get Docker system info"
          exit 1
        }
        
        BUILD_END_TIME=$(date +%s)
        BUILD_DURATION=$((BUILD_END_TIME - BUILD_START_TIME))
        
        # Move cache to avoid growing cache
        rm -rf /tmp/.buildx-cache
        mv /tmp/.buildx-cache-new /tmp/.buildx-cache
        
        echo "‚úÖ Docker image built successfully in ${BUILD_DURATION}s"
        echo "BUILD_DURATION=${BUILD_DURATION}" >> $GITHUB_ENV
        
        echo "Image details:"
        docker images ptt-telegram-scheduler:${{ github.sha }} --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}"

    - name: Test Docker image with comprehensive health checks
      run: |
        echo "=== Docker Image Testing ==="
        
        # Start container with health check
        docker run --rm -d --name test-container -p 3000:3000 \
          --health-cmd="curl -f http://localhost:3000/api/health || exit 1" \
          --health-interval=5s \
          --health-timeout=3s \
          --health-retries=3 \
          ptt-telegram-scheduler:latest || {
          echo "‚ùå Failed to start test container"
          exit 1
        }
        
        # Wait for container to be ready
        echo "Waiting for container to be ready..."
        for i in {1..30}; do
          if docker exec test-container curl -f http://localhost:3000/api/health >/dev/null 2>&1; then
            echo "‚úÖ Container is healthy"
            break
          fi
          if [ $i -eq 30 ]; then
            echo "‚ùå Container health check timeout"
            echo "Container logs:"
            docker logs test-container
            docker stop test-container
            exit 1
          fi
          sleep 2
        done
        
        # Additional health checks
        echo "Running additional health checks..."
        curl -f http://localhost:3000/api/health || {
          echo "‚ùå Health endpoint check failed"
          echo "Container logs:"
          docker logs test-container
          docker stop test-container
          exit 1
        }
        
        docker stop test-container
        echo "‚úÖ Docker image testing completed successfully"

    - name: Save Docker image with compression
      run: |
        echo "=== Docker Image Export ==="
        docker save ptt-telegram-scheduler:${{ github.sha }} | gzip > ptt-telegram-scheduler.tar.gz
        
        echo "Compressed image size:"
        ls -lh ptt-telegram-scheduler.tar.gz
        echo "‚úÖ Docker image saved successfully"

    - name: Upload build artifacts with enhanced metadata
      uses: actions/upload-artifact@v4
      with:
        name: build-artifacts-${{ github.sha }}
        path: |
          .next/
          ptt-telegram-scheduler.tar.gz
        retention-days: 7

    - name: Build failure diagnostics
      if: failure()
      run: |
        echo "=== Build Failure Diagnostics ==="
        echo "System information:"
        echo "  Available memory: $(free -h || echo 'N/A')"
        echo "  Available disk space: $(df -h . || echo 'N/A')"
        echo "  Docker system info:"
        docker system df || echo "Docker system info unavailable"
        
        echo "Build artifacts:"
        ls -la .next/ || echo ".next directory not found"
        
        echo "Docker images:"
        docker images || echo "Unable to list Docker images"
        
        echo "Recent logs:"
        if [ -f ~/.npm/_logs/*.log ]; then
          tail -50 ~/.npm/_logs/*.log || echo "No npm logs found"
        fi

  monitoring:
    name: CI/CD Monitoring & Reporting
    runs-on: ubuntu-latest
    needs: [test, security, build]
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Download test artifacts
      uses: actions/download-artifact@v4
      with:
        pattern: test-results-*
        merge-multiple: true
      continue-on-error: true

    - name: Download security scan results
      uses: actions/download-artifact@v4
      with:
        name: security-scan-results
      continue-on-error: true

    - name: Setup Node.js for monitoring
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies for monitoring
      run: npm ci --silent

    - name: Run comprehensive performance monitoring
      run: |
        echo "=== Running Performance Monitoring ==="
        npm run perf:monitor || {
          echo "‚ö†Ô∏è Performance monitoring failed, continuing with basic report"
        }

    - name: Generate CI/CD performance report
      run: |
        echo "=== CI/CD Pipeline Performance Report ===" > pipeline-report.md
        echo "" >> pipeline-report.md
        echo "**Pipeline Run Information:**" >> pipeline-report.md
        echo "- Run ID: ${{ github.run_id }}" >> pipeline-report.md
        echo "- Run Number: ${{ github.run_number }}" >> pipeline-report.md
        echo "- Commit SHA: ${{ github.sha }}" >> pipeline-report.md
        echo "- Branch: ${{ github.ref_name }}" >> pipeline-report.md
        echo "- Triggered by: ${{ github.event_name }}" >> pipeline-report.md
        echo "- Actor: ${{ github.actor }}" >> pipeline-report.md
        echo "" >> pipeline-report.md
        
        echo "**Job Status Summary:**" >> pipeline-report.md
        echo "- Test Job: ${{ needs.test.result }}" >> pipeline-report.md
        echo "- Security Job: ${{ needs.security.result }}" >> pipeline-report.md
        echo "- Build Job: ${{ needs.build.result }}" >> pipeline-report.md
        echo "" >> pipeline-report.md
        
        # Add test results summary if available
        if [ -f test-results/junit.xml ]; then
          echo "**Test Results Summary:**" >> pipeline-report.md
          echo '```' >> pipeline-report.md
          grep -E "(tests|failures|errors|skipped)" test-results/junit.xml | head -5 >> pipeline-report.md || echo "Test summary unavailable" >> pipeline-report.md
          echo '```' >> pipeline-report.md
          echo "" >> pipeline-report.md
        fi
        
        # Add coverage summary if available
        if [ -f coverage/coverage-summary.json ]; then
          echo "**Coverage Summary:**" >> pipeline-report.md
          echo '```json' >> pipeline-report.md
          cat coverage/coverage-summary.json | jq '.total' >> pipeline-report.md || echo "Coverage summary unavailable" >> pipeline-report.md
          echo '```' >> pipeline-report.md
          echo "" >> pipeline-report.md
        fi
        
        echo "**Recommendations:**" >> pipeline-report.md
        if [ "${{ needs.test.result }}" != "success" ]; then
          echo "- ‚ùå Test job failed - Review test logs and fix failing tests" >> pipeline-report.md
        fi
        if [ "${{ needs.security.result }}" != "success" ]; then
          echo "- ‚ùå Security scan failed - Address security vulnerabilities" >> pipeline-report.md
        fi
        if [ "${{ needs.build.result }}" != "success" ]; then
          echo "- ‚ùå Build job failed - Check build configuration and dependencies" >> pipeline-report.md
        fi
        if [ "${{ needs.test.result }}" == "success" ] && [ "${{ needs.security.result }}" == "success" ] && [ "${{ needs.build.result }}" == "success" ]; then
          echo "- ‚úÖ All jobs completed successfully - Ready for deployment" >> pipeline-report.md
        fi

    - name: Track workflow performance metrics
      run: |
        echo "=== Tracking Workflow Performance ==="
        ./scripts/workflow-performance-tracker.sh || {
          echo "‚ö†Ô∏è Performance tracking failed, continuing without metrics"
        }
      env:
        TEST_JOB_RESULT: ${{ needs.test.result }}
        SECURITY_JOB_RESULT: ${{ needs.security.result }}
        BUILD_JOB_RESULT: ${{ needs.build.result }}

    - name: Upload pipeline report and performance data
      uses: actions/upload-artifact@v4
      with:
        name: pipeline-report-${{ github.run_id }}
        path: |
          pipeline-report.md
          ci-performance-report.md
          .github/performance-data/
        retention-days: 30

    - name: Comment PR with pipeline status
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          let report = '';
          try {
            report = fs.readFileSync('pipeline-report.md', 'utf8');
          } catch (error) {
            report = 'Pipeline report generation failed';
          }
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: `## üöÄ CI/CD Pipeline Report\n\n${report}`
          });

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [build, monitoring]
    if: github.ref == 'refs/heads/develop' && needs.build.result == 'success'
    environment: staging
    timeout-minutes: 15
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Google Cloud CLI
      uses: google-github-actions/setup-gcloud@v1
      with:
        service_account_key: ${{ secrets.GCP_SA_KEY_STAGING }}
        project_id: ${{ secrets.GOOGLE_CLOUD_PROJECT_STAGING }}

    - name: Configure Docker for GCR
      run: gcloud auth configure-docker

    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: build-artifacts-${{ github.sha }}

    - name: Load Docker image
      run: docker load < ptt-telegram-scheduler.tar.gz

    - name: Tag and push to GCR
      run: |
        docker tag ptt-telegram-scheduler:${{ github.sha }} gcr.io/${{ secrets.GOOGLE_CLOUD_PROJECT_STAGING }}/ptt-telegram-scheduler:${{ github.sha }}
        docker tag ptt-telegram-scheduler:${{ github.sha }} gcr.io/${{ secrets.GOOGLE_CLOUD_PROJECT_STAGING }}/ptt-telegram-scheduler:staging
        docker push gcr.io/${{ secrets.GOOGLE_CLOUD_PROJECT_STAGING }}/ptt-telegram-scheduler:${{ github.sha }}
        docker push gcr.io/${{ secrets.GOOGLE_CLOUD_PROJECT_STAGING }}/ptt-telegram-scheduler:staging

    - name: Deploy to Cloud Run (Staging)
      run: |
        gcloud run deploy ptt-telegram-scheduler-staging \
          --image gcr.io/${{ secrets.GOOGLE_CLOUD_PROJECT_STAGING }}/ptt-telegram-scheduler:${{ github.sha }} \
          --platform managed \
          --region us-central1 \
          --allow-unauthenticated \
          --set-env-vars NODE_ENV=staging \
          --set-env-vars GOOGLE_CLOUD_PROJECT=${{ secrets.GOOGLE_CLOUD_PROJECT_STAGING }}

    - name: Deploy Cloud Function (Staging)
      run: |
        gcloud functions deploy ptt-scraper-staging \
          --source functions/ptt-scraper \
          --runtime python39 \
          --trigger-http \
          --allow-unauthenticated \
          --set-env-vars GOOGLE_CLOUD_PROJECT=${{ secrets.GOOGLE_CLOUD_PROJECT_STAGING }}

    - name: Update Cloud Scheduler (Staging)
      run: |
        gcloud scheduler jobs update http ptt-scraper-job-staging \
          --uri=$(gcloud functions describe ptt-scraper-staging --format="value(httpsTrigger.url)") \
          --schedule="*/15 * * * *" \
          --http-method=POST

    - name: Run smoke tests
      run: |
        STAGING_URL=$(gcloud run services describe ptt-telegram-scheduler-staging --platform managed --region us-central1 --format "value(status.url)")
        curl -f $STAGING_URL/api/health
        npm run test:smoke -- --baseUrl=$STAGING_URL

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [build, monitoring]
    if: github.ref == 'refs/heads/main' && needs.build.result == 'success'
    environment: production
    timeout-minutes: 20
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Google Cloud CLI
      uses: google-github-actions/setup-gcloud@v1
      with:
        service_account_key: ${{ secrets.GCP_SA_KEY_PRODUCTION }}
        project_id: ${{ secrets.GOOGLE_CLOUD_PROJECT }}

    - name: Configure Docker for GCR
      run: gcloud auth configure-docker

    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: build-artifacts-${{ github.sha }}

    - name: Load Docker image
      run: docker load < ptt-telegram-scheduler.tar.gz

    - name: Tag and push to GCR
      run: |
        docker tag ptt-telegram-scheduler:${{ github.sha }} gcr.io/${{ secrets.GOOGLE_CLOUD_PROJECT }}/ptt-telegram-scheduler:${{ github.sha }}
        docker tag ptt-telegram-scheduler:${{ github.sha }} gcr.io/${{ secrets.GOOGLE_CLOUD_PROJECT }}/ptt-telegram-scheduler:latest
        docker push gcr.io/${{ secrets.GOOGLE_CLOUD_PROJECT }}/ptt-telegram-scheduler:${{ github.sha }}
        docker push gcr.io/${{ secrets.GOOGLE_CLOUD_PROJECT }}/ptt-telegram-scheduler:latest

    - name: Deploy to Cloud Run (Production)
      run: |
        gcloud run deploy ptt-telegram-scheduler \
          --image gcr.io/${{ secrets.GOOGLE_CLOUD_PROJECT }}/ptt-telegram-scheduler:${{ github.sha }} \
          --platform managed \
          --region us-central1 \
          --allow-unauthenticated \
          --set-env-vars NODE_ENV=production \
          --set-env-vars GOOGLE_CLOUD_PROJECT=${{ secrets.GOOGLE_CLOUD_PROJECT }} \
          --min-instances=1 \
          --max-instances=10 \
          --cpu=1 \
          --memory=512Mi

    - name: Deploy Cloud Function (Production)
      run: |
        gcloud functions deploy ptt-scraper \
          --source functions/ptt-scraper \
          --runtime python39 \
          --trigger-http \
          --allow-unauthenticated \
          --set-env-vars GOOGLE_CLOUD_PROJECT=${{ secrets.GOOGLE_CLOUD_PROJECT }} \
          --memory=512MB \
          --timeout=540s

    - name: Update Cloud Scheduler (Production)
      run: |
        gcloud scheduler jobs update http ptt-scraper-job \
          --uri=$(gcloud functions describe ptt-scraper --format="value(httpsTrigger.url)") \
          --schedule="*/15 * * * *" \
          --http-method=POST \
          --time-zone="Asia/Taipei"

    - name: Run production health checks
      run: |
        PRODUCTION_URL=$(gcloud run services describe ptt-telegram-scheduler --platform managed --region us-central1 --format "value(status.url)")
        curl -f $PRODUCTION_URL/api/health
        
        # Wait for deployment to stabilize
        sleep 30
        
        # Run comprehensive health checks
        npm run test:health-check -- --baseUrl=$PRODUCTION_URL

    - name: Create GitHub release
      if: startsWith(github.ref, 'refs/tags/')
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ github.ref }}
        release_name: Release ${{ github.ref }}
        draft: false
        prerelease: false

  notify:
    name: Enhanced Notification & Reporting
    runs-on: ubuntu-latest
    needs: [test, security, build, monitoring, deploy-staging, deploy-production]
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}

    - name: Generate comprehensive status report
      run: |
        echo "=== Comprehensive Pipeline Status Report ===" > final-report.md
        echo "" >> final-report.md
        echo "**Pipeline Execution Summary:**" >> final-report.md
        echo "- Run ID: ${{ github.run_id }}" >> final-report.md
        echo "- Run Number: ${{ github.run_number }}" >> final-report.md
        echo "- Commit SHA: ${{ github.sha }}" >> final-report.md
        echo "- Branch: ${{ github.ref_name }}" >> final-report.md
        echo "- Triggered by: ${{ github.event_name }}" >> final-report.md
        echo "- Actor: ${{ github.actor }}" >> final-report.md
        echo "- Timestamp: $(date -u)" >> final-report.md
        echo "" >> final-report.md
        
        echo "**Job Status Summary:**" >> final-report.md
        echo "- üß™ Test Job: ${{ needs.test.result }}" >> final-report.md
        echo "- üîí Security Job: ${{ needs.security.result }}" >> final-report.md
        echo "- üèóÔ∏è Build Job: ${{ needs.build.result }}" >> final-report.md
        echo "- üìä Monitoring Job: ${{ needs.monitoring.result }}" >> final-report.md
        
        if [ "${{ needs.deploy-staging.result }}" != "skipped" ]; then
          echo "- üöÄ Staging Deploy: ${{ needs.deploy-staging.result }}" >> final-report.md
        fi
        
        if [ "${{ needs.deploy-production.result }}" != "skipped" ]; then
          echo "- üåü Production Deploy: ${{ needs.deploy-production.result }}" >> final-report.md
        fi
        
        echo "" >> final-report.md
        
        # Determine overall status
        overall_status="success"
        if [ "${{ needs.test.result }}" == "failure" ] || [ "${{ needs.security.result }}" == "failure" ] || [ "${{ needs.build.result }}" == "failure" ]; then
          overall_status="failure"
        elif [ "${{ needs.deploy-staging.result }}" == "failure" ] || [ "${{ needs.deploy-production.result }}" == "failure" ]; then
          overall_status="deployment_failure"
        fi
        
        echo "OVERALL_STATUS=$overall_status" >> $GITHUB_ENV
        
        if [ "$overall_status" == "success" ]; then
          echo "üéâ **Overall Status: SUCCESS**" >> final-report.md
          echo "" >> final-report.md
          echo "All pipeline stages completed successfully!" >> final-report.md
        elif [ "$overall_status" == "failure" ]; then
          echo "‚ùå **Overall Status: FAILURE**" >> final-report.md
          echo "" >> final-report.md
          echo "**Critical Issues Detected:**" >> final-report.md
          if [ "${{ needs.test.result }}" == "failure" ]; then
            echo "- Tests failed - Review test logs and fix failing tests" >> final-report.md
          fi
          if [ "${{ needs.security.result }}" == "failure" ]; then
            echo "- Security scan failed - Address security vulnerabilities" >> final-report.md
          fi
          if [ "${{ needs.build.result }}" == "failure" ]; then
            echo "- Build failed - Check build configuration and dependencies" >> final-report.md
          fi
        elif [ "$overall_status" == "deployment_failure" ]; then
          echo "‚ö†Ô∏è **Overall Status: DEPLOYMENT FAILURE**" >> final-report.md
          echo "" >> final-report.md
          echo "Build and tests passed, but deployment failed. Check deployment logs." >> final-report.md
        fi
        
        echo "" >> final-report.md
        echo "**Quick Links:**" >> final-report.md
        echo "- [View Full Workflow Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> final-report.md
        echo "- [View Commit](https://github.com/${{ github.repository }}/commit/${{ github.sha }})" >> final-report.md
        if [ "${{ github.event_name }}" == "pull_request" ]; then
          echo "- [View Pull Request](https://github.com/${{ github.repository }}/pull/${{ github.event.number }})" >> final-report.md
        fi

    - name: Upload final report
      uses: actions/upload-artifact@v4
      with:
        name: final-pipeline-report-${{ github.run_id }}
        path: final-report.md
        retention-days: 30

    - name: Notify Slack on Success
      if: env.OVERALL_STATUS == 'success' && secrets.SLACK_WEBHOOK_URL
      uses: 8398a7/action-slack@v3
      with:
        status: success
        channel: '#deployments'
        text: |
          üéâ PTT Telegram Scheduler pipeline completed successfully!
          
          üìã **Details:**
          ‚Ä¢ Branch: ${{ github.ref_name }}
          ‚Ä¢ Commit: ${{ github.sha }}
          ‚Ä¢ Environment: ${{ github.ref == 'refs/heads/main' && 'Production' || 'Staging' }}
          ‚Ä¢ Run: #${{ github.run_number }}
          
          üîó [View Details](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

    - name: Notify Slack on Failure
      if: env.OVERALL_STATUS != 'success' && secrets.SLACK_WEBHOOK_URL
      uses: 8398a7/action-slack@v3
      with:
        status: failure
        channel: '#deployments'
        text: |
          üö® PTT Telegram Scheduler pipeline failed!
          
          üìã **Details:**
          ‚Ä¢ Branch: ${{ github.ref_name }}
          ‚Ä¢ Commit: ${{ github.sha }}
          ‚Ä¢ Status: ${{ env.OVERALL_STATUS }}
          ‚Ä¢ Run: #${{ github.run_number }}
          
          ‚ùó **Failed Jobs:**
          ${{ needs.test.result == 'failure' && '‚Ä¢ Tests' || '' }}
          ${{ needs.security.result == 'failure' && '‚Ä¢ Security Scan' || '' }}
          ${{ needs.build.result == 'failure' && '‚Ä¢ Build' || '' }}
          ${{ needs.deploy-staging.result == 'failure' && '‚Ä¢ Staging Deployment' || '' }}
          ${{ needs.deploy-production.result == 'failure' && '‚Ä¢ Production Deployment' || '' }}
          
          üîó [View Logs](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

    - name: Create GitHub issue on critical failure
      if: env.OVERALL_STATUS == 'failure'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('final-report.md', 'utf8');
          
          // Check for existing open issues for this type of failure
          const issues = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            state: 'open',
            labels: 'ci-failure'
          });
          
          const recentIssue = issues.data.find(issue => {
            const createdAt = new Date(issue.created_at);
            const oneDayAgo = new Date(Date.now() - 24 * 60 * 60 * 1000);
            return createdAt > oneDayAgo && issue.title.includes('CI/CD Pipeline Failure');
          });
          
          if (!recentIssue) {
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üö® CI/CD Pipeline Failure - Run #${{ github.run_number }}`,
              body: `## Pipeline Failure Report\n\n${report}\n\n---\n\n**Troubleshooting Steps:**\n1. Check the failed job logs for specific error messages\n2. Verify all dependencies are properly installed\n3. Ensure all tests pass locally before pushing\n4. Check for any configuration changes that might affect the build\n\n*This issue was automatically created by the CI/CD monitoring system.*`,
              labels: ['ci-failure', 'bug', 'priority-high', 'automated']
            });
          } else {
            // Update existing issue with new failure information
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: recentIssue.number,
              body: `## Additional Failure - Run #${{ github.run_number }}\n\n${report}\n\n*Updated automatically by CI/CD monitoring system.*`
            });
          }

  cleanup:
    name: Cleanup
    runs-on: ubuntu-latest
    needs: [deploy-staging, deploy-production]
    if: always()
    
    steps:
    - name: Cleanup old Docker images
      run: |
        # This would typically connect to GCR and clean up old images
        echo "Cleanup job - would remove images older than 30 days"
        
    - name: Cleanup old artifacts
      uses: actions/github-script@v6
      with:
        script: |
          const artifacts = await github.rest.actions.listArtifactsForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
          });
          
          const oldArtifacts = artifacts.data.artifacts.filter(artifact => {
            const createdAt = new Date(artifact.created_at);
            const thirtyDaysAgo = new Date(Date.now() - 30 * 24 * 60 * 60 * 1000);
            return createdAt < thirtyDaysAgo;
          });
          
          for (const artifact of oldArtifacts) {
            await github.rest.actions.deleteArtifact({
              owner: context.repo.owner,
              repo: context.repo.repo,
              artifact_id: artifact.id,
            });
            console.log(`Deleted artifact: ${artifact.name}`);
          }